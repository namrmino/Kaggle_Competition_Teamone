{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n\n\n\nimport os","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# 데이터 불러오기\ntrain = pd.read_csv('/kaggle/input/kakr-4th-competition/train.csv')\ntest = pd.read_csv('/kaggle/input/kakr-4th-competition/test.csv')\nsample_submission = pd.read_csv('../input/kakr-4th-competition/sample_submission.csv')\n\nlabel = train['income']\n\ndel train['income']","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 라벨 값 인코딩\nlabel = label.map(lambda x: 1 if x == '>50K' else 0)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_valid, y_train, y_valid = train_test_split(train, label, \n                                                          test_size=0.2,\n                                                          random_state=20,\n                                                          shuffle=True)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(x_train, x_valid, x_test):\n    \n    global tmp_x_train\n    global tmp_x_valid\n    global tmp_x_test\n    \n    tmp_x_train = x_train.copy()\n    tmp_x_valid = x_valid.copy()\n    tmp_x_test  = x_test.copy()\n    \n    tmp_x_train = tmp_x_train.reset_index(drop=True)\n    tmp_x_valid = tmp_x_valid.reset_index(drop=True)\n    tmp_x_test  = tmp_x_test.reset_index(drop=True)\n    \n    # column 제거\n    tmp_x_train.drop(['id','fnlwgt','education','relationship','native_country','workclass'], axis=1, inplace=True)\n    tmp_x_valid.drop(['id','fnlwgt','education','relationship','native_country','workclass'], axis=1, inplace=True)\n    tmp_x_test.drop(['id','fnlwgt','education','relationship','native_country','workclass'], axis=1, inplace=True)\n    \n    # marital status\n    tmp_x_train['marital_status'] = (tmp_x_train['marital_status'] == 'Married-civ-spouse').astype(int)\n    tmp_x_valid['marital_status'] = (tmp_x_valid['marital_status'] == 'Married-civ-spouse').astype(int)\n    tmp_x_test['marital_status'] = (tmp_x_test['marital_status'] == 'Married-civ-spouse').astype(int)\n    \n    # race\n    tmp_x_train['race'] = ((tmp_x_train['race'] == 'White') | (tmp_x_train['race'] == 'Asian-Pac-Islander')).astype(int)\n    tmp_x_valid['race'] = ((tmp_x_valid['race'] == 'White') | (tmp_x_valid['race'] == 'Asian-Pac-Islander')).astype(int)\n    tmp_x_test['race'] = ((tmp_x_test['race'] == 'White') | (tmp_x_test['race'] == 'Asian-Pac-Islander')).astype(int)\n    \n    # capital_gain, loss\n    tmp_x_train['cap_gain_high'] = (tmp_x_train['capital_gain'] != 0).astype(int)\n    tmp_x_train['cap_loss_high'] = (tmp_x_train['capital_loss'] >= 1700).astype(int)\n    tmp_x_train['capital_gain'] = tmp_x_train['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n    \n    tmp_x_valid['cap_gain_high'] = (tmp_x_valid['capital_gain'] != 0).astype(int)\n    tmp_x_valid['cap_loss_high'] = (tmp_x_valid['capital_loss'] >= 1700).astype(int)\n    tmp_x_valid['capital_gain'] = tmp_x_valid['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n    \n    tmp_x_test['cap_gain_high'] = (tmp_x_test['capital_gain'] != 0).astype(int)\n    tmp_x_test['cap_loss_high'] = (tmp_x_test['capital_loss'] >= 1700).astype(int)\n    tmp_x_test['capital_gain'] = tmp_x_test['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n    \n    # age\n    tmp_x_train.loc[tmp_x_train['age'] < 20, 'age_range'] = '~20'\n    tmp_x_train.loc[tmp_x_train['age'] >= 65, 'age_range'] = '~65'\n    down = 20\n    for i in range(45//5):\n        tmp_x_train.loc[(tmp_x_train['age'] >= down) & (tmp_x_train['age'] < down+5), 'age_range'] = str(down)+'~'+str(down+5)\n        down += 5\n    tmp_x_train['age'] = tmp_x_train['age_range']\n    tmp_x_train.drop(['age_range'], axis=1, inplace=True)\n    \n    tmp_x_valid.loc[tmp_x_valid['age'] < 20, 'age_range'] = '~20'\n    tmp_x_valid.loc[tmp_x_valid['age'] >= 65, 'age_range'] = '~65'\n    down = 20\n    for i in range(45//5):\n        tmp_x_valid.loc[(tmp_x_valid['age'] >= down) & (tmp_x_valid['age'] < down+5), 'age_range'] = str(down)+'~'+str(down+5)\n        down += 5\n    tmp_x_valid['age'] = tmp_x_valid['age_range']\n    tmp_x_valid.drop(['age_range'], axis=1, inplace=True)\n    \n    tmp_x_test.loc[tmp_x_test['age'] < 20, 'age_range'] = '~20'\n    tmp_x_test.loc[tmp_x_test['age'] >= 65, 'age_range'] = '~65'\n    down = 20\n    for i in range(45//5):\n        tmp_x_test.loc[(tmp_x_test['age'] >= down) & (tmp_x_test['age'] < down+5), 'age_range'] = str(down)+'~'+str(down+5)\n        down += 5\n    tmp_x_test['age'] = tmp_x_test['age_range']\n    tmp_x_test.drop(['age_range'], axis=1, inplace=True)\n        \n    # edu_num\n    tmp_x_train['edu_num_high'] = (tmp_x_train['education_num'] >= 13).astype(int)\n    tmp_x_valid['edu_num_high'] = (tmp_x_valid['education_num'] >= 13).astype(int)\n    tmp_x_test['edu_num_high'] = (tmp_x_test['education_num'] >= 13).astype(int)\n    \n    # hours-per-week\n    tmp_x_train['hpw_high'] = (tmp_x_train['hours_per_week'] >= 50).astype(int)\n    tmp_x_valid['hpw_high'] = (tmp_x_valid['hours_per_week'] >= 50).astype(int)\n    tmp_x_test['hpw_high'] = (tmp_x_test['hours_per_week'] >= 50).astype(int)\n    \n    # min-max scaler\n    mmscaler = MinMaxScaler()\n    tmp_x_train['education_num'] = mmscaler.fit_transform(tmp_x_train['education_num'].values.reshape(-1,1))\n    tmp_x_valid['education_num'] = mmscaler.transform(tmp_x_valid['education_num'].values.reshape(-1,1))\n    tmp_x_test['education_num'] = mmscaler.transform(tmp_x_test['education_num'].values.reshape(-1,1))\n    \n    tmp_x_train['hours_per_week'] = mmscaler.fit_transform(tmp_x_train['hours_per_week'].values.reshape(-1,1))\n    tmp_x_valid['hours_per_week'] = mmscaler.transform(tmp_x_valid['hours_per_week'].values.reshape(-1,1))\n    tmp_x_test['hours_per_week'] = mmscaler.transform(tmp_x_test['hours_per_week'].values.reshape(-1,1))\n\n    \n    # ohe\n    tmp_all = pd.concat([tmp_x_train, tmp_x_valid, tmp_x_test])\n    \n    ohe = OneHotEncoder(sparse=False)\n    cat_columns = ['age', 'marital_status', 'occupation', 'race', 'sex']\n    ohe.fit(tmp_all[cat_columns])\n    \n    \n    ohe_columns = list()\n    for lst in ohe.categories_:\n        ohe_columns += lst.tolist()\n    \n    tmp_train_cat = pd.DataFrame(ohe.transform(tmp_x_train[cat_columns]), columns=ohe_columns)\n    tmp_valid_cat = pd.DataFrame(ohe.transform(tmp_x_valid[cat_columns]), columns=ohe_columns)\n    tmp_test_cat  = pd.DataFrame(ohe.transform(tmp_x_test[cat_columns]), columns=ohe_columns)\n    \n    tmp_train_cat.columns = ohe.get_feature_names(cat_columns)\n    tmp_valid_cat.columns = ohe.get_feature_names(cat_columns)\n    tmp_test_cat.columns = ohe.get_feature_names(cat_columns)\n    \n    tmp_x_train = pd.concat([tmp_x_train, tmp_train_cat], axis=1)\n    tmp_x_valid = pd.concat([tmp_x_valid, tmp_valid_cat], axis=1)\n    tmp_x_test = pd.concat([tmp_x_test, tmp_test_cat], axis=1)\n\n    tmp_x_train = tmp_x_train.drop(columns=cat_columns)\n    tmp_x_valid = tmp_x_valid.drop(columns=cat_columns)\n    tmp_x_test = tmp_x_test.drop(columns=cat_columns)\n        \n#     # get_dummies\n#     tmp_x_train = pd.get_dummies(tmp_x_train, columns = ['age', 'marital_status', 'occupation', 'race', 'sex'])\n#     tmp_x_valid = pd.get_dummies(tmp_x_valid, columns = ['age', 'marital_status', 'occupation', 'race', 'sex'])\n#     tmp_x_test = pd.get_dummies(tmp_x_test, columns = ['age', 'marital_status', 'occupation', 'race', 'sex'])\n    \n    \n    return tmp_x_train.values, tmp_x_valid.values, tmp_x_test.values","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_x_train","execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'tmp_x_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-cffff666408a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp_x_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tmp_x_train' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocess(x_train, x_valid, test)","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"(array([[0.66666667, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.53333333, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.53333333, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        ...,\n        [0.8       , 0.        , 0.        , ..., 1.        , 1.        ,\n         0.        ],\n        [0.8       , 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.53333333, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ]]),\n array([[0.53333333, 0.        , 0.        , ..., 1.        , 1.        ,\n         0.        ],\n        [0.86666667, 0.        , 0.        , ..., 0.        , 0.        ,\n         1.        ],\n        [0.6       , 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        ...,\n        [0.53333333, 0.        , 0.        , ..., 1.        , 1.        ,\n         0.        ],\n        [0.8       , 8.94741595, 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.86666667, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ]]),\n array([[0.6       , 0.        , 0.        , ..., 1.        , 1.        ,\n         0.        ],\n        [0.53333333, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.6       , 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        ...,\n        [0.13333333, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.53333333, 0.        , 0.        , ..., 1.        , 0.        ,\n         1.        ],\n        [0.53333333, 0.        , 0.        , ..., 1.        , 1.        ,\n         0.        ]]))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_x_train.describe()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"       education_num  capital_gain  capital_loss  hours_per_week  \\\ncount   20839.000000  20839.000000  20839.000000    20839.000000   \nmean        0.605579      0.733625     88.000432        0.402335   \nstd         0.170939      2.454261    403.795858        0.126457   \nmin         0.000000      0.000000      0.000000        0.000000   \n25%         0.533333      0.000000      0.000000        0.397959   \n50%         0.600000      0.000000      0.000000        0.397959   \n75%         0.733333      0.000000      0.000000        0.448980   \nmax         1.000000     11.512915   4356.000000        1.000000   \n\n       cap_gain_high  cap_loss_high  edu_num_high      hpw_high     age_20~25  \\\ncount   20839.000000   20839.000000  20839.000000  20839.000000  20839.000000   \nmean        0.083113       0.034503      0.248332      0.200681      0.123518   \nstd         0.276060       0.182521      0.432056      0.400520      0.329039   \nmin         0.000000       0.000000      0.000000      0.000000      0.000000   \n25%         0.000000       0.000000      0.000000      0.000000      0.000000   \n50%         0.000000       0.000000      0.000000      0.000000      0.000000   \n75%         0.000000       0.000000      0.000000      0.000000      0.000000   \nmax         1.000000       1.000000      1.000000      1.000000      1.000000   \n\n          age_25~30  ...  occupation_Priv-house-serv  \\\ncount  20839.000000  ...                20839.000000   \nmean       0.129517  ...                    0.004943   \nstd        0.335779  ...                    0.070132   \nmin        0.000000  ...                    0.000000   \n25%        0.000000  ...                    0.000000   \n50%        0.000000  ...                    0.000000   \n75%        0.000000  ...                    0.000000   \nmax        1.000000  ...                    1.000000   \n\n       occupation_Prof-specialty  occupation_Protective-serv  \\\ncount               20839.000000                20839.000000   \nmean                    0.126302                    0.019387   \nstd                     0.332197                    0.137883   \nmin                     0.000000                    0.000000   \n25%                     0.000000                    0.000000   \n50%                     0.000000                    0.000000   \n75%                     0.000000                    0.000000   \nmax                     1.000000                    1.000000   \n\n       occupation_Sales  occupation_Tech-support  occupation_Transport-moving  \\\ncount      20839.000000             20839.000000                 20839.000000   \nmean           0.116368                 0.028264                     0.049187   \nstd            0.320674                 0.165731                     0.216263   \nmin            0.000000                 0.000000                     0.000000   \n25%            0.000000                 0.000000                     0.000000   \n50%            0.000000                 0.000000                     0.000000   \n75%            0.000000                 0.000000                     0.000000   \nmax            1.000000                 1.000000                     1.000000   \n\n             race_0        race_1    sex_Female      sex_Male  \ncount  20839.000000  20839.000000  20839.000000  20839.000000  \nmean       0.113201      0.886799      0.332598      0.667402  \nstd        0.316846      0.316846      0.471155      0.471155  \nmin        0.000000      0.000000      0.000000      0.000000  \n25%        0.000000      1.000000      0.000000      0.000000  \n50%        0.000000      1.000000      0.000000      1.000000  \n75%        0.000000      1.000000      1.000000      1.000000  \nmax        1.000000      1.000000      1.000000      1.000000  \n\n[8 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>education_num</th>\n      <th>capital_gain</th>\n      <th>capital_loss</th>\n      <th>hours_per_week</th>\n      <th>cap_gain_high</th>\n      <th>cap_loss_high</th>\n      <th>edu_num_high</th>\n      <th>hpw_high</th>\n      <th>age_20~25</th>\n      <th>age_25~30</th>\n      <th>...</th>\n      <th>occupation_Priv-house-serv</th>\n      <th>occupation_Prof-specialty</th>\n      <th>occupation_Protective-serv</th>\n      <th>occupation_Sales</th>\n      <th>occupation_Tech-support</th>\n      <th>occupation_Transport-moving</th>\n      <th>race_0</th>\n      <th>race_1</th>\n      <th>sex_Female</th>\n      <th>sex_Male</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>...</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n      <td>20839.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.605579</td>\n      <td>0.733625</td>\n      <td>88.000432</td>\n      <td>0.402335</td>\n      <td>0.083113</td>\n      <td>0.034503</td>\n      <td>0.248332</td>\n      <td>0.200681</td>\n      <td>0.123518</td>\n      <td>0.129517</td>\n      <td>...</td>\n      <td>0.004943</td>\n      <td>0.126302</td>\n      <td>0.019387</td>\n      <td>0.116368</td>\n      <td>0.028264</td>\n      <td>0.049187</td>\n      <td>0.113201</td>\n      <td>0.886799</td>\n      <td>0.332598</td>\n      <td>0.667402</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.170939</td>\n      <td>2.454261</td>\n      <td>403.795858</td>\n      <td>0.126457</td>\n      <td>0.276060</td>\n      <td>0.182521</td>\n      <td>0.432056</td>\n      <td>0.400520</td>\n      <td>0.329039</td>\n      <td>0.335779</td>\n      <td>...</td>\n      <td>0.070132</td>\n      <td>0.332197</td>\n      <td>0.137883</td>\n      <td>0.320674</td>\n      <td>0.165731</td>\n      <td>0.216263</td>\n      <td>0.316846</td>\n      <td>0.316846</td>\n      <td>0.471155</td>\n      <td>0.471155</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.533333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.397959</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.600000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.397959</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.733333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.448980</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>11.512915</td>\n      <td>4356.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 40 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_x_test.describe().T","execution_count":19,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DataFrame' object has no attribute 't'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-a9c9da910c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp_x_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 't'"]}]},{"metadata":{},"cell_type":"markdown","source":"# 일단 k-fold 한번 돌려보고\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nn_splits = 5\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_scores = list()\noof_pred = np.zeros((test.shape[0],))\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n    \n    # 전처리\n    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n    # 모델 정의\n    clf = LGBMClassifier()\n    \n    # 모델 학습\n    clf.fit(x_train, y_train,\n            eval_set = [[x_valid, y_valid]], \n            eval_metric = 'logloss',        \n            early_stopping_rounds = 100,\n            verbose = 100,  )\n\n    # 훈련, 검증 데이터 Log Loss 확인\n    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n    \n    val_scores.append(val_f1_score)\n    \n\n# 교차 검증 F1 Score 평균 계산하기\nprint('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","execution_count":9,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.280645\nDid not meet early stopping. Best iteration is:\n[100]\tvalid_0's binary_logloss: 0.280645\n0 Fold, train f1_score : 0.87984, validation f1_score : 0.8695\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.28152\nDid not meet early stopping. Best iteration is:\n[99]\tvalid_0's binary_logloss: 0.281508\n1 Fold, train f1_score : 0.88144, validation f1_score : 0.8670\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.285252\nDid not meet early stopping. Best iteration is:\n[95]\tvalid_0's binary_logloss: 0.285136\n2 Fold, train f1_score : 0.88094, validation f1_score : 0.8651\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.283011\nDid not meet early stopping. Best iteration is:\n[98]\tvalid_0's binary_logloss: 0.282902\n3 Fold, train f1_score : 0.88134, validation f1_score : 0.8656\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.278725\nDid not meet early stopping. Best iteration is:\n[97]\tvalid_0's binary_logloss: 0.278615\n4 Fold, train f1_score : 0.87984, validation f1_score : 0.8702\n\nCross Validation Score : 0.8675\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"a1 = clf.predict(tmp_x_valid)\nprint(f\"LightGBM F1 Score: {f1_score(y_valid, a1, average='micro')}\")","execution_count":10,"outputs":[{"output_type":"stream","text":"LightGBM F1 Score: 0.87022461124976\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### oof"},{"metadata":{"trusted":true},"cell_type":"code","source":"# logistic regression\n\nval_scores = list()\noof_pred = np.zeros((test.shape[0], )) # 이것도 달라짐\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n    \n    # 전처리\n    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n    # 모델 정의\n    clf = LogisticRegression()\n    \n    # 모델 학습\n    clf.fit(x_train, y_train)\n\n    # 훈련, 검증 데이터 F1 Score 확인\n    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n    \n    val_scores.append(val_f1_score)\n    \n    oof_pred += clf.predict_proba(x_test)[: , 1] / n_splits # 이게 달라진거임\n    \n\n# 교차 검증 F1 Score 평균 계산하기\nprint('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","execution_count":11,"outputs":[{"output_type":"stream","text":"0 Fold, train f1_score : 0.84424, validation f1_score : 0.8468\n\n1 Fold, train f1_score : 0.84584, validation f1_score : 0.8428\n\n2 Fold, train f1_score : 0.84424, validation f1_score : 0.8440\n\n3 Fold, train f1_score : 0.84574, validation f1_score : 0.8438\n\n4 Fold, train f1_score : 0.84434, validation f1_score : 0.8472\n\nCross Validation Score : 0.8449\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_pred","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"array([0.0143961 , 0.60567547, 0.00367895, ..., 0.09177444, 0.267417  ,\n       0.00633541])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### stacking"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_scores = list()\n\nnew_x_train_list = [np.zeros((train.shape[0], 1)) for _ in range(4)]\nnew_x_test_list  = [np.zeros((test.shape[0], 1)) for _ in range(4)]\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n    print(f\"Fold {i} Start\")\n    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n    \n    # 전처리\n    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n    \n    # 모델 정의\n    clfs = [LGBMClassifier()] # 추가 모델 입력\n    \n    for model_idx, clf in enumerate(clfs):\n        clf.fit(x_train, y_train)\n        \n        new_x_train_list[model_idx][val_idx, :] = clf.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n        new_x_test_list[model_idx][:] += clf.predict_proba(x_test)[:, 1].reshape(-1, 1) / n_splits","execution_count":12,"outputs":[{"output_type":"stream","text":"Fold 0 Start\nFold 1 Start\nFold 2 Start\nFold 3 Start\nFold 4 Start\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.DataFrame(np.concatenate(new_x_train_list, axis=1), columns=None)\nnew_label = label\nnew_test = pd.DataFrame(np.concatenate(new_x_test_list, axis=1), columns=None)\n\nnew_train.shape, new_label.shape, new_test.shape","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"((26049, 4), (26049,), (6512, 4))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_f1(y, t, threshold=0.5):\n    t = t.get_label()\n    y_bin = (y > threshold).astype(int) \n    return 'f1', f1_score(t, y_bin, average='micro')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_scores = list()\noof_pred = np.zeros((test.shape[0], ))\n\nfor i, (trn_idx, val_idx) in enumerate(skf.split(new_train, new_label)):\n    x_train, y_train = new_train.iloc[trn_idx, :], new_label[trn_idx]\n    x_valid, y_valid = new_train.iloc[val_idx, :], new_label[val_idx]\n    \n    # 전처리\n    scaler = StandardScaler()\n    x_train = scaler.fit_transform(x_train)\n    x_valid = scaler.transform(x_valid)\n    x_test  = scaler.transform(new_test)\n    \n    # 모델 정의\n    clf = LGBMClassifier()\n    #clf = XGBClassifier(tree_method='gpu_hist')\n    \n    # 모델 학습\n    clf.fit(x_train, y_train,\n            eval_set = [[x_valid, y_valid]], \n            eval_metric = 'logloss',        # 모델에 따라 판단 (xgbosst : xgb_f1)\n            early_stopping_rounds = 100,\n            verbose = 100,  )\n\n    # 훈련, 검증 데이터 F1 Score 확인\n    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n    \n    val_scores.append(val_f1_score)\n    \n    oof_pred += clf.predict_proba(x_test)[:, 1] / n_splits\n    \n\n# 교차 검증 F1 Score 평균 계산하기\nprint('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))","execution_count":21,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.284819\nDid not meet early stopping. Best iteration is:\n[50]\tvalid_0's binary_logloss: 0.282398\n0 Fold, train f1_score : 0.86854, validation f1_score : 0.8701\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.283984\nDid not meet early stopping. Best iteration is:\n[55]\tvalid_0's binary_logloss: 0.282714\n1 Fold, train f1_score : 0.86854, validation f1_score : 0.8660\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.287994\nDid not meet early stopping. Best iteration is:\n[52]\tvalid_0's binary_logloss: 0.286446\n2 Fold, train f1_score : 0.86914, validation f1_score : 0.8641\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.28799\nDid not meet early stopping. Best iteration is:\n[49]\tvalid_0's binary_logloss: 0.285979\n3 Fold, train f1_score : 0.86924, validation f1_score : 0.8643\n\nTraining until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.286128\nDid not meet early stopping. Best iteration is:\n[45]\tvalid_0's binary_logloss: 0.281401\n4 Fold, train f1_score : 0.86904, validation f1_score : 0.8698\n\nCross Validation Score : 0.8669\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이거 되는지 확인","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building models\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nimport time\nimport sys\n\n#tuning hyperparameters\nfrom bayes_opt import BayesianOptimization\nfrom skopt  import BayesSearchCV \n\n#metrics \nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport shap","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef lgb_f1_score(y_hat, data):\n    y_true = data.get_label()\n    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n    return 'f1', f1_score(y_true, y_hat), True","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bayes_parameter_opt_lgb(X, y, init_round=20, opt_round=30, n_folds=5, random_seed=6, n_estimators=10000,\n                            learning_rate=0.05, output_process=False):\n    # prepare data\n\n    train_data = lgb.Dataset(data=X, label=y)\n    # parameters\n\n    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, max_depth, \n                 lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n        \n        global cv_result\n\n        params = {'objective':'binary','num_iterations':1000, 'learning_rate':0.05,\n                  'early_stopping_round':100, 'metric':'binary_logloss'} #rmse\n        params[\"num_leaves\"] = int(round(num_leaves))\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n        params['max_depth'] = int(round(max_depth))\n        params['lambda_l1'] = max(lambda_l1, 0)\n        params['lambda_l2'] = max(lambda_l2, 0)\n        params['min_split_gain'] = min_split_gain\n        params['min_child_weight'] = min_child_weight\n        \n        cv_result = lgb.cv(params, train_data, nfold=3, seed=random_seed,\n                           stratified=False, verbose_eval =200, metrics=['binary_logloss']) #rmse\n\n        return min(cv_result['binary_logloss-mean']) #  여기서 에러...\n\n    # setting range of the parameters\n    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (24, 45),\n                                            'feature_fraction': (0.1, 0.9),\n                                            'bagging_fraction': (0.5, 1),\n                                            'max_depth': (5, 8.99),\n                                            'lambda_l1': (0, 5),\n                                            'lambda_l2': (0, 3),\n                                            'min_split_gain': (0.001, 0.1),\n                                            'min_child_weight': (5, 60)}, random_state=0)\n    # optimize\n    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n    \n    # output optimization process\n    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n    \n    # return\n    return lgbBO\n\nopt_params = bayes_parameter_opt_lgb(tmp_x_train, y_train, init_round=5, opt_round=10, n_folds=3,\n                                     random_seed=6, n_estimators=10000, learning_rate=0.05)","execution_count":24,"outputs":[{"output_type":"stream","text":"|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | max_depth | min_ch... | min_sp... | num_le... |\n-------------------------------------------------------------------------------------------------------------------------\n[200]\tcv_agg's binary_logloss: 0.305371 + 0.00716862\n[400]\tcv_agg's binary_logloss: 0.303903 + 0.00741055\n[600]\tcv_agg's binary_logloss: 0.303098 + 0.00741458\n[800]\tcv_agg's binary_logloss: 0.302444 + 0.00740958\n[1000]\tcv_agg's binary_logloss: 0.301924 + 0.00739532\n| \u001b[0m 1       \u001b[0m | \u001b[0m 0.3019  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 0.6722  \u001b[0m | \u001b[0m 3.014   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 6.69    \u001b[0m | \u001b[0m 40.52   \u001b[0m | \u001b[0m 0.04432 \u001b[0m | \u001b[0m 42.73   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.310054 + 0.00746455\n[400]\tcv_agg's binary_logloss: 0.308554 + 0.00785947\n[600]\tcv_agg's binary_logloss: 0.30809 + 0.00787684\n[800]\tcv_agg's binary_logloss: 0.307634 + 0.00787019\n[1000]\tcv_agg's binary_logloss: 0.30726 + 0.00786974\n| \u001b[95m 2       \u001b[0m | \u001b[95m 0.3073  \u001b[0m | \u001b[95m 0.9818  \u001b[0m | \u001b[95m 0.4068  \u001b[0m | \u001b[95m 3.959   \u001b[0m | \u001b[95m 1.587   \u001b[0m | \u001b[95m 7.266   \u001b[0m | \u001b[95m 55.91   \u001b[0m | \u001b[95m 0.008033\u001b[0m | \u001b[95m 25.83   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.308119 + 0.00727592\n[400]\tcv_agg's binary_logloss: 0.306917 + 0.00743599\n[600]\tcv_agg's binary_logloss: 0.306149 + 0.00750106\n[800]\tcv_agg's binary_logloss: 0.305567 + 0.00753973\n[1000]\tcv_agg's binary_logloss: 0.305103 + 0.00760087\n| \u001b[0m 3       \u001b[0m | \u001b[0m 0.3051  \u001b[0m | \u001b[0m 0.5101  \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.891   \u001b[0m | \u001b[0m 2.61    \u001b[0m | \u001b[0m 8.905   \u001b[0m | \u001b[0m 48.95   \u001b[0m | \u001b[0m 0.04669 \u001b[0m | \u001b[0m 40.39   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.301738 + 0.00605881\n[400]\tcv_agg's binary_logloss: 0.299214 + 0.00638553\n[600]\tcv_agg's binary_logloss: 0.298327 + 0.00637071\n[800]\tcv_agg's binary_logloss: 0.29756 + 0.00642364\n[1000]\tcv_agg's binary_logloss: 0.296938 + 0.00645225\n| \u001b[0m 4       \u001b[0m | \u001b[0m 0.2969  \u001b[0m | \u001b[0m 0.5591  \u001b[0m | \u001b[0m 0.6119  \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 2.834   \u001b[0m | \u001b[0m 7.082   \u001b[0m | \u001b[0m 27.81   \u001b[0m | \u001b[0m 0.02719 \u001b[0m | \u001b[0m 40.26   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.304675 + 0.00720238\n[400]\tcv_agg's binary_logloss: 0.303111 + 0.00766027\n[600]\tcv_agg's binary_logloss: 0.302224 + 0.00773153\n[800]\tcv_agg's binary_logloss: 0.301435 + 0.00769982\n[1000]\tcv_agg's binary_logloss: 0.300828 + 0.00768233\n| \u001b[0m 5       \u001b[0m | \u001b[0m 0.3008  \u001b[0m | \u001b[0m 0.7281  \u001b[0m | \u001b[0m 0.5547  \u001b[0m | \u001b[0m 0.09395 \u001b[0m | \u001b[0m 1.853   \u001b[0m | \u001b[0m 7.442   \u001b[0m | \u001b[0m 38.93   \u001b[0m | \u001b[0m 0.09443 \u001b[0m | \u001b[0m 38.32   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.31125 + 0.00708102\n[400]\tcv_agg's binary_logloss: 0.309874 + 0.007226\n[600]\tcv_agg's binary_logloss: 0.30933 + 0.00721302\n[800]\tcv_agg's binary_logloss: 0.308879 + 0.00718773\n[1000]\tcv_agg's binary_logloss: 0.308504 + 0.00716958\n| \u001b[95m 6       \u001b[0m | \u001b[95m 0.3085  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.8669  \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 0.0     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 60.0    \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 45.0    \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.32338 + 0.00528713\n[400]\tcv_agg's binary_logloss: 0.312057 + 0.00667976\n[600]\tcv_agg's binary_logloss: 0.309731 + 0.00706046\n[800]\tcv_agg's binary_logloss: 0.308772 + 0.00723763\n[1000]\tcv_agg's binary_logloss: 0.308263 + 0.00736592\n| \u001b[0m 7       \u001b[0m | \u001b[0m 0.3083  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 35.34   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.325504 + 0.00516763\n[400]\tcv_agg's binary_logloss: 0.313694 + 0.00664163\n[600]\tcv_agg's binary_logloss: 0.311274 + 0.00701583\n[800]\tcv_agg's binary_logloss: 0.310428 + 0.0072099\n[1000]\tcv_agg's binary_logloss: 0.310067 + 0.00732811\n| \u001b[95m 8       \u001b[0m | \u001b[95m 0.3101  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 3.0     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 60.0    \u001b[0m | \u001b[95m 0.001   \u001b[0m | \u001b[95m 34.81   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.324812 + 0.0051673\n[400]\tcv_agg's binary_logloss: 0.313374 + 0.00665499\n[600]\tcv_agg's binary_logloss: 0.311059 + 0.00701923\n[800]\tcv_agg's binary_logloss: 0.310143 + 0.00723345\n[1000]\tcv_agg's binary_logloss: 0.3098 + 0.00735279\n| \u001b[0m 9       \u001b[0m | \u001b[0m 0.3098  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 34.81   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.311236 + 0.00687988\n[400]\tcv_agg's binary_logloss: 0.309508 + 0.00732577\n[600]\tcv_agg's binary_logloss: 0.308834 + 0.00736677\n[800]\tcv_agg's binary_logloss: 0.308368 + 0.00732693\n[1000]\tcv_agg's binary_logloss: 0.307987 + 0.00729471\n| \u001b[0m 10      \u001b[0m | \u001b[0m 0.308   \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 32.9    \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.308405 + 0.00490709\n[400]\tcv_agg's binary_logloss: 0.292711 + 0.00587203\n[600]\tcv_agg's binary_logloss: 0.289177 + 0.00622676\n[800]\tcv_agg's binary_logloss: 0.28821 + 0.00627938\n[1000]\tcv_agg's binary_logloss: 0.287573 + 0.00635569\n| \u001b[0m 11      \u001b[0m | \u001b[0m 0.2876  \u001b[0m | \u001b[0m 0.769   \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 1.589   \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.325618 + 0.00520222\n[400]\tcv_agg's binary_logloss: 0.313894 + 0.00672521\n[600]\tcv_agg's binary_logloss: 0.311542 + 0.00703728\n[800]\tcv_agg's binary_logloss: 0.310968 + 0.00718845\n[1000]\tcv_agg's binary_logloss: 0.310697 + 0.00728031\n| \u001b[95m 12      \u001b[0m | \u001b[95m 0.3107  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 3.0     \u001b[0m | \u001b[95m 8.99    \u001b[0m | \u001b[95m 60.0    \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 45.0    \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.325618 + 0.00520222\n[400]\tcv_agg's binary_logloss: 0.313894 + 0.00672521\n[600]\tcv_agg's binary_logloss: 0.311542 + 0.00703728\n[800]\tcv_agg's binary_logloss: 0.310968 + 0.00718845\n[1000]\tcv_agg's binary_logloss: 0.310697 + 0.00728031\n| \u001b[95m 13      \u001b[0m | \u001b[95m 0.3107  \u001b[0m | \u001b[95m 0.5     \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 3.0     \u001b[0m | \u001b[95m 8.99    \u001b[0m | \u001b[95m 60.0    \u001b[0m | \u001b[95m 0.1     \u001b[0m | \u001b[95m 24.0    \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.311025 + 0.00691807\n[400]\tcv_agg's binary_logloss: 0.3099 + 0.00719312\n[600]\tcv_agg's binary_logloss: 0.309322 + 0.00718656\n[800]\tcv_agg's binary_logloss: 0.308847 + 0.00717107\n[1000]\tcv_agg's binary_logloss: 0.308471 + 0.00714391\n| \u001b[0m 14      \u001b[0m | \u001b[0m 0.3085  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 32.96   \u001b[0m |\n[200]\tcv_agg's binary_logloss: 0.32344 + 0.00530727\n[400]\tcv_agg's binary_logloss: 0.312213 + 0.0068096\n[600]\tcv_agg's binary_logloss: 0.310064 + 0.00723723\n[800]\tcv_agg's binary_logloss: 0.309512 + 0.00735029\n[1000]\tcv_agg's binary_logloss: 0.309144 + 0.00743423\n| \u001b[0m 15      \u001b[0m | \u001b[0m 0.3091  \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 8.99    \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.1     \u001b[0m | \u001b[0m 24.0    \u001b[0m |\n=========================================================================================================================\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = opt_params.max['params']","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"{'bagging_fraction': 0.5,\n 'feature_fraction': 0.1,\n 'lambda_l1': 5.0,\n 'lambda_l2': 3.0,\n 'max_depth': 8.99,\n 'min_child_weight': 60.0,\n 'min_split_gain': 0.1,\n 'num_leaves': 24.0}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n    \"objective\" : \"binary\",\n    \"metric\" : \"binary_logloss\", \n    \"bagging_frequency\" : 5,\n    \"bagging_seed\" : 2018,\n    \"verbosity\" : -1,\n\n    # Selected rounded-off params\n    'bagging_fraction': 0.5,\n    'feature_fraction': 0.1,\n    'lambda_l1': 5.0,\n    'lambda_l2': 3.0,\n    'max_depth': 9,\n    'min_child_weight': 60.0,\n    'min_split_gain': 0.1,\n    'num_leaves': 24\n}","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nd_train = lgb.Dataset(tmp_x_train, label=y_train)\nd_test = lgb.Dataset(tmp_x_valid, label=y_valid)\nclf = lgb.train(params, d_train, 1000, d_test, verbose_eval=100, early_stopping_rounds=100)\n\ny_pred = clf.predict(x_valid)","execution_count":31,"outputs":[{"output_type":"stream","text":"Training until validation scores don't improve for 100 rounds\n[100]\tvalid_0's binary_logloss: 0.322878\n[200]\tvalid_0's binary_logloss: 0.305433\n[300]\tvalid_0's binary_logloss: 0.301195\n[400]\tvalid_0's binary_logloss: 0.300539\n[500]\tvalid_0's binary_logloss: 0.300222\n[600]\tvalid_0's binary_logloss: 0.300006\n[700]\tvalid_0's binary_logloss: 0.299766\n[800]\tvalid_0's binary_logloss: 0.299593\n[900]\tvalid_0's binary_logloss: 0.299381\n[1000]\tvalid_0's binary_logloss: 0.299214\nDid not meet early stopping. Best iteration is:\n[997]\tvalid_0's binary_logloss: 0.299214\n","name":"stdout"},{"output_type":"error","ename":"LightGBMError","evalue":"The number of features in data (4) is not the same as it was in training data (40).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-c530515a1d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2413\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2414\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \"\"\"\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLightGBMError\u001b[0m: The number of features in data (4) is not the same as it was in training data (40)."]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sklearn.model_selection as model_selection","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_lgb(train_X, train_y, val_X, val_y, test_X):\n    lgtrain = lgb.Dataset(train_X, label=train_y)\n    lgval = lgb.Dataset(val_X, label=val_y)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 1000, valid_sets=[lgval], early_stopping_rounds=100, \n                      verbose_eval=100, evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result\n\npred_test = 0\nkf = model_selection.KFold(n_splits=5, random_state=2018, shuffle=True)\nfor dev_index, val_index in kf.split(train):\n    \n        # 전처리\n    x_train, x_valid, x_test = preprocess(x_train, x_valid, test)\n\n    dev_X, val_X = x_train.loc[dev_index,:], x_train.loc[val_index,:]\n    dev_y, val_y = x_valid[dev_index], x_valid[val_index]\n    \n    pred_test_tmp, model, evals_result = run_lgb(dev_X, dev_y, val_X, val_y, test_X)\n    pred_test += pred_test_tmp\npred_test /= 5.","execution_count":36,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'reset_index'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-8a8161cd0e47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 전처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdev_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdev_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-3d46c9db6eb2>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(x_train, x_valid, x_test)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtmp_x_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtmp_x_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_x_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtmp_x_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_x_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtmp_x_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtmp_x_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'reset_index'"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}