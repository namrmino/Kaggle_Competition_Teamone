{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OOF & Stacking_NJJ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSqFFzqfUApe",
        "outputId": "49a8303e-225c-4d1c-856a-795e9ab55139"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS2bhYGITtPl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import os"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzEw8PkZT9fG"
      },
      "source": [
        "# 데이터 불러오기\n",
        "train = pd.read_csv('/content/drive/My Drive/[2020]_데이터분석캠프(캐글코리아)/data/train.csv')\n",
        "test = pd.read_csv('/content/drive/My Drive/[2020]_데이터분석캠프(캐글코리아)/data/test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/My Drive/[2020]_데이터분석캠프(캐글코리아)/data/sample_submission.csv')"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g-Kir22nbL1"
      },
      "source": [
        "# income 별도로 할당\n",
        "label = train['income']\n",
        "del train['income']"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysQA0zA9UJ9U"
      },
      "source": [
        "# 1) column 제거\n",
        "def col_reduction(df):\n",
        "    df.drop(['id','fnlwgt','education','relationship','native_country','workclass'], axis=1, inplace=True)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# 2) marital_status 조정\n",
        "def mar_st(df):\n",
        "    df['marital_status'] = (df['marital_status'] == 'Married-civ-spouse').astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# 3) race 조정\n",
        "def race(df):\n",
        "    df['race'] = ((train['race'] == 'White') | (train['race'] == 'Asian-Pac-Islander')).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 4) capital_gain, loss 조정\n",
        "def capital(df):\n",
        "    df['cap_gain_high'] = (df['capital_gain'] != 0).astype(int)\n",
        "    df['cap_loss_high'] = (df['capital_loss'] >= 1700).astype(int)\n",
        "    df['capital_gain'] = df['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# 5) age 조정 함수\n",
        "def age(df):\n",
        "    df.loc[df['age'] < 20, 'age_range'] = '~20'\n",
        "    df.loc[df['age'] >= 65, 'age_range'] = '~65'\n",
        "\n",
        "    down = 20\n",
        "    for i in range(45//5):\n",
        "        df.loc[(df['age'] >= down) & (df['age'] < down+5), 'age_range'] = str(down)+'~'+str(down+5)\n",
        "        down += 5\n",
        "\n",
        "    df['age'] = df['age_range']\n",
        "    df.drop(['age_range'], axis=1, inplace=True)\n",
        "    \n",
        "    return df\n",
        "    \n",
        "# 6) One-hot encoding은 만들지 않았다.\n",
        "\n",
        "# 7) edu_num 새 변수 만들기\n",
        "def edu(df):\n",
        "    df['edu_num_high'] = (df['education_num'] >= 13).astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# 8) hpw 새 변수 만들기\n",
        "    \n",
        "def hpw(df):\n",
        "    df['hpw_high'] = (df['hours_per_week'] >= 50).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 9) MinMaxScaler\n",
        "def mm_feature(df, feature):\n",
        "    mm_scaler = MinMaxScaler()\n",
        "    \n",
        "    df[feature] = mm_scaler.fit_transform(df[feature].values.reshape(-1,1))\n",
        "    \n",
        "    return df, mm_scaler\n",
        "\n",
        "def main(df):\n",
        "    \n",
        "    df1 = col_reduction(df)\n",
        "    df2 = mar_st(df1)\n",
        "    df3 = race(df2)\n",
        "    df4 = capital(df3)\n",
        "    df5 = age(df4)\n",
        "    \n",
        "    df6 = pd.get_dummies(df5)\n",
        "    \n",
        "    df7 = edu(df6)\n",
        "    df_fin = hpw(df7)\n",
        "    \n",
        "    return df_fin"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybjHOgyUMKc"
      },
      "source": [
        "# 적용\n",
        "## main: 1) ~ 7)\n",
        "train = main(train)\n",
        "X_test = main(test)\n",
        "\n",
        "## 8) minmax scaler\n",
        "train, mm_scaler1 = mm_feature(train,'education_num')\n",
        "train, mm_scaler2 = mm_feature(train,'hours_per_week')\n",
        "\n",
        "X_test['education_num'] = mm_scaler1.transform(X_test['education_num'].values.reshape(-1,1))\n",
        "X_test['hours_per_week'] = mm_scaler2.transform(X_test['hours_per_week'].values.reshape(-1,1))"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWNUU6cwdfql"
      },
      "source": [
        "## XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR2P3UcEVm_P"
      },
      "source": [
        "OOF(Out of fold) 앙상블"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dk7TLU0Z82k"
      },
      "source": [
        "def xgb_f1(y, t, threshold=0.5):\n",
        "    t = t.get_label()\n",
        "    y_bin = (y > threshold).astype(int) \n",
        "    return 'f1', f1_score(t, y_bin, average='micro')"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPaNEgtcZaND"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqO2LYRUVZqT",
        "outputId": "3f7ee0d4-52ed-44c2-89d2-69fe06c82705"
      },
      "source": [
        "val_scores = list()\n",
        "oof_pred = np.zeros((test.shape[0], ))\n",
        "\n",
        "for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n",
        "    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n",
        "    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n",
        "\n",
        "    # 모델 정의\n",
        "    clf = XGBClassifier(tree_method='gpu_hist', learning_rate=0.1, max_depth=5, n_estimators=200)\n",
        "    \n",
        "    # 모델 학습\n",
        "    clf.fit(x_train, y_train,\n",
        "            eval_set = [[x_valid, y_valid]], \n",
        "            eval_metric = xgb_f1,        \n",
        "            early_stopping_rounds = 100,\n",
        "            verbose = 100,  )\n",
        "\n",
        "    # 훈련, 검증 데이터 F1 Score 확인\n",
        "    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n",
        "    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n",
        "    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n",
        "    \n",
        "    val_scores.append(val_f1_score)\n",
        "    \n",
        "    oof_pred += clf.predict_proba(X_test)[: , 1] / n_splits\n",
        "    \n",
        "\n",
        "# 교차 검증 F1 Score 평균 계산하기\n",
        "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.150288\tvalidation_0-f1:0.849712\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.130518\tvalidation_0-f1:0.869482\n",
            "Stopping. Best iteration:\n",
            "[1]\tvalidation_0-error:0.150672\tvalidation_0-f1:0.849328\n",
            "\n",
            "0 Fold, train f1_score : 0.85174, validation f1_score : 0.8493\n",
            "\n",
            "[0]\tvalidation_0-error:0.144914\tvalidation_0-f1:0.855086\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.131862\tvalidation_0-f1:0.868138\n",
            "Stopping. Best iteration:\n",
            "[6]\tvalidation_0-error:0.145681\tvalidation_0-f1:0.854319\n",
            "\n",
            "1 Fold, train f1_score : 0.85344, validation f1_score : 0.8543\n",
            "\n",
            "[0]\tvalidation_0-error:0.15048\tvalidation_0-f1:0.84952\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.136468\tvalidation_0-f1:0.863532\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-error:0.152207\tvalidation_0-f1:0.847793\n",
            "\n",
            "2 Fold, train f1_score : 0.85244, validation f1_score : 0.8478\n",
            "\n",
            "[0]\tvalidation_0-error:0.152015\tvalidation_0-f1:0.847985\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.134165\tvalidation_0-f1:0.865835\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-error:0.152015\tvalidation_0-f1:0.847985\n",
            "\n",
            "3 Fold, train f1_score : 0.85264, validation f1_score : 0.8480\n",
            "\n",
            "[0]\tvalidation_0-error:0.148973\tvalidation_0-f1:0.851027\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.132463\tvalidation_0-f1:0.867537\n",
            "Stopping. Best iteration:\n",
            "[5]\tvalidation_0-error:0.149549\tvalidation_0-f1:0.850451\n",
            "\n",
            "4 Fold, train f1_score : 0.85374, validation f1_score : 0.8505\n",
            "\n",
            "Cross Validation Score : 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOtAK-I3tAhQ",
        "outputId": "10b800e0-491f-4711-a4c0-a7fdb5e26843"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {'max_depth': [1, 3, 5], 'n_estimators': [50, 100, 200], 'learning_rate':[1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(XGBClassifier(), param_grid, cv=skf)\n",
        "grid.fit(x_train, y_train)\n",
        "best_param = grid.best_params_\n",
        "best_param"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-c2qgr8uxH_",
        "outputId": "d9973fc8-3fd6-4b1b-d2f8-59be49084cbb"
      },
      "source": [
        "param_grid = {'max_depth': [1, 3, 5], 'n_estimators': [50, 100, 200], 'learning_rate':[1, 0.1, 0.01]}\n",
        "grid = GridSearchCV(LGBMClassifier(), param_grid, cv=skf)\n",
        "grid.fit(x_train, y_train)\n",
        "best_param = grid.best_params_\n",
        "best_param"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJwrpkS0u88T",
        "outputId": "f40de0c7-1218-45c3-a3d6-2443625ea8cc"
      },
      "source": [
        "param_grid = {'n_estimators': [50, 100], 'max_depth': [1,3,8], 'min_samples_leaf' : [3,5], 'min_samples_split' : [2,3]}\n",
        "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=skf)\n",
        "grid.fit(x_train, y_train)\n",
        "best_param = grid.best_params_\n",
        "best_param"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 8,\n",
              " 'min_samples_leaf': 3,\n",
              " 'min_samples_split': 3,\n",
              " 'n_estimators': 100}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W820SX7UVuwx"
      },
      "source": [
        "Stacking 앙상블"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dcYJjQ_d1Nx"
      },
      "source": [
        "1) 1stage 결과 모으기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tB5DnA4VvEZ",
        "outputId": "4ceb4d9e-0878-4b24-f833-cf2743b143cb"
      },
      "source": [
        "val_scores = list()\n",
        "\n",
        "new_x_train_list = [np.zeros((train.shape[0], 1)) for _ in range(4)]\n",
        "new_x_test_list  = [np.zeros((test.shape[0], 1)) for _ in range(4)]\n",
        "\n",
        "for i, (trn_idx, val_idx) in enumerate(skf.split(train, label)):\n",
        "    print(f\"Fold {i} Start\")\n",
        "    x_train, y_train = train.iloc[trn_idx, :], label[trn_idx]\n",
        "    x_valid, y_valid = train.iloc[val_idx, :], label[val_idx]\n",
        "    \n",
        "    # 모델 정의\n",
        "    clfs = [LogisticRegression(), \n",
        "            RandomForestClassifier(max_depth=8, min_samples_leaf=3, min_samples_split=3, n_estimators=100), \n",
        "            XGBClassifier(tree_method='gpu_hist', learning_rate=0.1, max_depth=5, n_estimators=200), \n",
        "            LGBMClassifier(tree_method='gpu_hist', learning_rate=0.1, max_depth=3, n_estimators=100)]\n",
        "    \n",
        "    for model_idx, clf in enumerate(clfs):\n",
        "        clf.fit(x_train, y_train)\n",
        "        \n",
        "        new_x_train_list[model_idx][val_idx, :] = clf.predict_proba(x_valid)[:, 1].reshape(-1, 1)\n",
        "        new_x_test_list[model_idx][:] += clf.predict_proba(X_test)[:, 1].reshape(-1, 1) / n_splits"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold 0 Start\n",
            "Fold 1 Start\n",
            "Fold 2 Start\n",
            "Fold 3 Start\n",
            "Fold 4 Start\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WtpU2Bwd4qc",
        "outputId": "03cf6099-4ce9-4a54-fcc2-3e49e66b9da3"
      },
      "source": [
        "new_x_train_list"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.49376718],\n",
              "        [0.00732824],\n",
              "        [0.00519227],\n",
              "        ...,\n",
              "        [0.02395131],\n",
              "        [0.01862802],\n",
              "        [0.0028776 ]]), array([[0.3333572 ],\n",
              "        [0.02738925],\n",
              "        [0.02032642],\n",
              "        ...,\n",
              "        [0.10603042],\n",
              "        [0.03774399],\n",
              "        [0.01027037]]), array([[4.00399953e-01],\n",
              "        [2.27430311e-04],\n",
              "        [3.96051793e-04],\n",
              "        ...,\n",
              "        [2.95416694e-02],\n",
              "        [1.38997380e-02],\n",
              "        [1.19783112e-03]]), array([[0.34725056],\n",
              "        [0.00262793],\n",
              "        [0.00305666],\n",
              "        ...,\n",
              "        [0.056839  ],\n",
              "        [0.02229105],\n",
              "        [0.0035949 ]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9sVIwp8d51y",
        "outputId": "57abc85d-96e4-412f-e0f7-7092ac30adec"
      },
      "source": [
        "new_x_test_list"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.01223078],\n",
              "        [0.6285043 ],\n",
              "        [0.00392437],\n",
              "        ...,\n",
              "        [0.11047058],\n",
              "        [0.27313894],\n",
              "        [0.00647557]]), array([[0.02499106],\n",
              "        [0.40293896],\n",
              "        [0.01886291],\n",
              "        ...,\n",
              "        [0.15012637],\n",
              "        [0.24072328],\n",
              "        [0.02159666]]), array([[0.00563361],\n",
              "        [0.36332088],\n",
              "        [0.00066725],\n",
              "        ...,\n",
              "        [0.01375558],\n",
              "        [0.25483002],\n",
              "        [0.00182497]]), array([[0.01815481],\n",
              "        [0.45455368],\n",
              "        [0.00255925],\n",
              "        ...,\n",
              "        [0.05293122],\n",
              "        [0.27285783],\n",
              "        [0.01126587]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOm2MJL4d8de",
        "outputId": "765d6cc8-ba95-4348-b6fb-4ba649bf7140"
      },
      "source": [
        "new_train = pd.DataFrame(np.concatenate(new_x_train_list, axis=1), columns=None)\n",
        "new_label = label\n",
        "new_test = pd.DataFrame(np.concatenate(new_x_test_list, axis=1), columns=None)\n",
        "\n",
        "new_train.shape, new_label.shape, new_test.shape"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26049, 4), (26049,), (6512, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXwIoErbeBva"
      },
      "source": [
        "2) 2stage meta model 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpSx_qATd9FO",
        "outputId": "ab77d5a9-8ea4-41b9-8524-3304120f2500"
      },
      "source": [
        "val_scores = list()\n",
        "oof_pred = np.zeros((test.shape[0], ))\n",
        "\n",
        "for i, (trn_idx, val_idx) in enumerate(skf.split(new_train, new_label)):\n",
        "    x_train, y_train = new_train.iloc[trn_idx, :], new_label[trn_idx]\n",
        "    x_valid, y_valid = new_train.iloc[val_idx, :], new_label[val_idx]\n",
        "    \n",
        "    # 전처리\n",
        "    scaler = StandardScaler()\n",
        "    x_train = scaler.fit_transform(x_train)\n",
        "    x_valid = scaler.transform(x_valid)\n",
        "    x_test  = scaler.transform(new_test)\n",
        "    \n",
        "    # 모델 정의\n",
        "    clf = XGBClassifier(tree_method='gpu_hist', learning_rate=0.1, max_depth=5, n_estimators=200)\n",
        "    \n",
        "    # 모델 학습\n",
        "    clf.fit(x_train, y_train,\n",
        "            eval_set = [[x_valid, y_valid]], \n",
        "            eval_metric = xgb_f1,        \n",
        "            early_stopping_rounds = 100,\n",
        "            verbose = 100,  )\n",
        "\n",
        "    # 훈련, 검증 데이터 F1 Score 확인\n",
        "    trn_f1_score = f1_score(y_train, clf.predict(x_train), average='micro')\n",
        "    val_f1_score = f1_score(y_valid, clf.predict(x_valid), average='micro')\n",
        "    print('{} Fold, train f1_score : {:.4f}4, validation f1_score : {:.4f}\\n'.format(i, trn_f1_score, val_f1_score))\n",
        "    \n",
        "    val_scores.append(val_f1_score)\n",
        "    \n",
        "    oof_pred += clf.predict_proba(x_test)[:, 1] / n_splits\n",
        "    \n",
        "\n",
        "# 교차 검증 F1 Score 평균 계산하기\n",
        "print('Cross Validation Score : {:.4f}'.format(np.mean(val_scores)))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-error:0.133589\tvalidation_0-f1:0.866411\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.132054\tvalidation_0-f1:0.867946\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-error:0.133589\tvalidation_0-f1:0.866411\n",
            "\n",
            "0 Fold, train f1_score : 0.87104, validation f1_score : 0.8664\n",
            "\n",
            "[0]\tvalidation_0-error:0.141267\tvalidation_0-f1:0.858733\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.134357\tvalidation_0-f1:0.865643\n",
            "Stopping. Best iteration:\n",
            "[0]\tvalidation_0-error:0.141267\tvalidation_0-f1:0.858733\n",
            "\n",
            "1 Fold, train f1_score : 0.86984, validation f1_score : 0.8587\n",
            "\n",
            "[0]\tvalidation_0-error:0.135701\tvalidation_0-f1:0.864299\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.138004\tvalidation_0-f1:0.861996\n",
            "[199]\tvalidation_0-error:0.13858\tvalidation_0-f1:0.86142\n",
            "2 Fold, train f1_score : 0.87974, validation f1_score : 0.8601\n",
            "\n",
            "[0]\tvalidation_0-error:0.136084\tvalidation_0-f1:0.863916\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.135893\tvalidation_0-f1:0.864107\n",
            "Stopping. Best iteration:\n",
            "[2]\tvalidation_0-error:0.138196\tvalidation_0-f1:0.861804\n",
            "\n",
            "3 Fold, train f1_score : 0.87184, validation f1_score : 0.8618\n",
            "\n",
            "[0]\tvalidation_0-error:0.131503\tvalidation_0-f1:0.868497\n",
            "Multiple eval metrics have been passed: 'validation_0-f1' will be used for early stopping.\n",
            "\n",
            "Will train until validation_0-f1 hasn't improved in 100 rounds.\n",
            "[100]\tvalidation_0-error:0.131503\tvalidation_0-f1:0.868497\n",
            "Stopping. Best iteration:\n",
            "[70]\tvalidation_0-error:0.134191\tvalidation_0-f1:0.865809\n",
            "\n",
            "4 Fold, train f1_score : 0.87174, validation f1_score : 0.8658\n",
            "\n",
            "Cross Validation Score : 0.8626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED3jxbhmv85Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}