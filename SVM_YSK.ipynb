{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"SVM_YSK.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"hPZOS9y1QX-u"},"source":["import numpy as np\n","import pandas as pd\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import missingno as msno\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.metrics import f1_score\n","from sklearn.svm import SVC\n","from sklearn.svm import LinearSVC\n","\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lbNyjn5yQX-u"},"source":["# 1. 이전까지의 방법으로 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"CxR5GhoPQX-u"},"source":["# 데이터 불러오기\n","train = pd.read_csv('./kakr-4th-competition/train.csv')\n","test = pd.read_csv('./kakr-4th-competition/test.csv')\n","sample_submission = pd.read_csv('./kakr-4th-competition/sample_submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xkT48xz1QX-u"},"source":["# 1) column 제거\n","def col_reduction(df):\n","    df.drop(['id','fnlwgt','education','relationship','native_country','workclass'], axis=1, inplace=True)\n","    \n","    return df\n","\n","# 2) marital_status 조정\n","def mar_st(df):\n","    df['marital_status'] = (df['marital_status'] == 'Married-civ-spouse').astype(int)\n","    \n","    return df\n","\n","# 3) capital_gain, loss 조정\n","def capital(df):\n","    df['cap_gain_high'] = (df['capital_gain'] != 0).astype(int)\n","    df['cap_loss_high'] = (df['capital_loss'] >= 1700).astype(int)\n","    df['capital_gain'] = df['capital_gain'].map(lambda x : np.log(x) if x != 0 else 0)\n","    \n","    return df\n","\n","# 4) age 조정 함수\n","def age(df):\n","    df.loc[df['age'] < 20, 'age_range'] = '~20'\n","    df.loc[df['age'] >= 65, 'age_range'] = '~65'\n","\n","    down = 20\n","    for i in range(45//5):\n","        df.loc[(df['age'] >= down) & (df['age'] < down+5), 'age_range'] = str(down)+'~'+str(down+5)\n","        down += 5\n","\n","    df['age'] = df['age_range']\n","    df.drop(['age_range'], axis=1, inplace=True)\n","    \n","    return df\n","    \n","# 5) One-hot encoding은 만들지 않았다.\n","\n","# 6) edu_num 새 변수 만들기\n","def edu(df):\n","    df['edu_num_high'] = (df['education_num'] >= 13).astype(int)\n","    \n","    return df\n","\n","# 7) hpw 새 변수 만들기\n","    \n","def hpw(df):\n","    df['hpw_high'] = (df['hours_per_week'] >= 50).astype(int)\n","\n","    return df\n","\n","# 8) MinMaxScaler\n","def mm_feature(df, feature):\n","    mm_scaler = MinMaxScaler()\n","    \n","    df[feature] = mm_scaler.fit_transform(df[feature].values.reshape(-1,1))\n","    \n","    return df, mm_scaler\n","\n","# 9) target 분리: train은 하고, test는 안하므로 따로 만들겠다.\n","def target_handle(df):\n","    df['income'] = df['income_>50K']\n","    df.drop(['income_>50K','income_<=50K'], axis=1, inplace=True)\n","    \n","    y_df = df.income\n","    X_df = df.drop(['income'], axis=1, inplace=False)\n","    \n","    return X_df, y_df\n","\n","def main(df):\n","    \n","    df1 = col_reduction(df)\n","    df2 = mar_st(df1)\n","    df3 = capital(df2)\n","    df4 = age(df3)\n","    \n","    df5 = pd.get_dummies(df4)\n","    \n","    df6 = edu(df5)\n","    df_fin = hpw(df6)\n","    \n","    return df_fin"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iGI9_hSvQX-u"},"source":["# 적용\n","## main: 1) ~ 7)\n","train = main(train)\n","X_test = main(test)\n","\n","## 8) minmax scaler\n","train, mm_scaler1 = mm_feature(train,'education_num')\n","train, mm_scaler2 = mm_feature(train,'hours_per_week')\n","\n","X_test['education_num'] = mm_scaler1.transform(X_test['education_num'].values.reshape(-1,1))\n","X_test['hours_per_week'] = mm_scaler2.transform(X_test['hours_per_week'].values.reshape(-1,1))\n","\n","## 9) X, y split\n","X_train, y_train = target_handle(train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LrIICvReQX-u"},"source":["# 2. 모델링 (+KFold (k = 5))\n","1. Linear SVM\n","    - penalty: 'l1', '12'\n","    - loss: 'square hinge', 'hinge'\n","    1. 'l2', 'square hinge': 0.85024\n","    2. '12', 'hinge': 0.8436\n","2. kernel = 'rbf'\n","    - gamma: 'scale', 'auto', float\n","    1. 'scale': 0.77286\n","    2. 'auto': 0.8560800000000001\n","3. kernel = 'poly'\n","    - gamma: 'scale', 'auto'\n","    - degree\n","    - coefficient\n","    1. 'scale': 0.77386\n","    2. 'auto': \n","4. kernel = 'sigmoid'\n","    - gamma: 'scale', 'auto'\n","    - coefficient\n","    1. 'scale': 0.7591800000000001\n","    2. 'auto': 0.77242"]},{"cell_type":"code","metadata":{"id":"qCJ5vvJWQX-u","outputId":"3b1096c5-efa5-4012-ed28-e66dddfb6673"},"source":["svm_clf1 = LinearSVC()\n","\n","# k = 5인 KFold와 Fold별 정확도를 담을 list 생성\n","kfold = KFold(n_splits=5) # default = 3\n","cv_accuracy = [] # 예측 성능을 list에 담을 것이다.\n","print('데이터 세트 크기:',X_train.shape[0])\n","\n","n_iter = 0\n","\n","# KFold.split( ) 호출: Fold 별 학습, 검증 Data의 row index를 array로 반환  \n","for train_index, test_index in kfold.split(X_train):\n","    \n","    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","    X_train_, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_, y_val = y_train[train_index], y_train[test_index]\n","    \n","    # 학습 및 예측 \n","    svm_clf1.fit(X_train_ , y_train_)    \n","    pred = svm_clf1.predict(X_val)\n","    n_iter += 1\n","    \n","    # 반복 시 마다 정확도 측정 \n","    accuracy = np.round(f1_score(y_val, pred, average='micro'), 4)\n","    train_size = X_train_.shape[0]\n","    test_size = X_val.shape[0]\n","    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n","          .format(n_iter, accuracy, train_size, test_size))\n","    cv_accuracy.append(accuracy)\n","    \n","# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n","print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터 세트 크기: 26049\n","\n","#1 교차 검증 정확도 :0.8551, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#2 교차 검증 정확도 :0.8514, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#3 교차 검증 정확도 :0.8653, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#4 교차 검증 정확도 :0.8445, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#5 교차 검증 정확도 :0.8349, 학습 데이터 크기: 20840, 검증 데이터 크기: 5209\n","\n","## 평균 검증 정확도: 0.85024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ia3GoHQSQX-v","outputId":"10d5ac54-ec00-4c2f-d67d-014d7faef5ae"},"source":["svm_clf2 = SVC(gamma = 'auto')\n","\n","# k = 5인 KFold와 Fold별 정확도를 담을 list 생성\n","kfold = KFold(n_splits=5) # default = 3\n","cv_accuracy = [] # 예측 성능을 list에 담을 것이다.\n","print('데이터 세트 크기:',X_train.shape[0])\n","\n","n_iter = 0\n","\n","# KFold.split( ) 호출: Fold 별 학습, 검증 Data의 row index를 array로 반환  \n","for train_index, test_index in kfold.split(X_train):\n","    \n","    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","    X_train_, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_, y_val = y_train[train_index], y_train[test_index]\n","    \n","    # 학습 및 예측 \n","    svm_clf2.fit(X_train_ , y_train_)    \n","    pred = svm_clf2.predict(X_val)\n","    n_iter += 1\n","    \n","    # 반복 시 마다 정확도 측정 \n","    accuracy = np.round(f1_score(y_val, pred, average='micro'), 4)\n","    train_size = X_train_.shape[0]\n","    test_size = X_val.shape[0]\n","    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n","          .format(n_iter, accuracy, train_size, test_size))\n","    cv_accuracy.append(accuracy)\n","    \n","# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n","print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터 세트 크기: 26049\n","\n","#1 교차 검증 정확도 :0.8582, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#2 교차 검증 정확도 :0.847, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#3 교차 검증 정확도 :0.8706, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#4 교차 검증 정확도 :0.8522, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#5 교차 검증 정확도 :0.8524, 학습 데이터 크기: 20840, 검증 데이터 크기: 5209\n","\n","## 평균 검증 정확도: 0.8560800000000001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Zm1-jduQX-v","outputId":"c672e84f-356a-43d1-835e-266580892fd5"},"source":["svm_clf3 = SVC(kernel = 'poly', gamma = 'auto')\n","\n","# k = 5인 KFold와 Fold별 정확도를 담을 list 생성\n","kfold = KFold(n_splits=5) # default = 3\n","cv_accuracy = [] # 예측 성능을 list에 담을 것이다.\n","print('데이터 세트 크기:',X_train.shape[0])\n","\n","n_iter = 0\n","\n","# KFold.split( ) 호출: Fold 별 학습, 검증 Data의 row index를 array로 반환  \n","for train_index, test_index in kfold.split(X_train):\n","    \n","    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","    X_train_, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_, y_val = y_train[train_index], y_train[test_index]\n","    \n","    # 학습 및 예측 \n","    svm_clf3.fit(X_train_ , y_train_)    \n","    pred = svm_clf3.predict(X_val)\n","    n_iter += 1\n","    \n","    # 반복 시 마다 정확도 측정 \n","    accuracy = np.round(f1_score(y_val, pred, average='micro'), 4)\n","    train_size = X_train_.shape[0]\n","    test_size = X_val.shape[0]\n","    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n","          .format(n_iter, accuracy, train_size, test_size))\n","    cv_accuracy.append(accuracy)\n","    \n","# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n","print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터 세트 크기: 26049\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b_3wp9Z6QX-v","outputId":"405e56bd-ecb2-4f50-e62d-257512181381"},"source":["svm_clf4 = SVC(kernel = 'sigmoid', gamma = 'auto')\n","\n","# k = 5인 KFold와 Fold별 정확도를 담을 list 생성\n","kfold = KFold(n_splits=5) # default = 3\n","cv_accuracy = [] # 예측 성능을 list에 담을 것이다.\n","print('데이터 세트 크기:',X_train.shape[0])\n","\n","n_iter = 0\n","\n","# KFold.split( ) 호출: Fold 별 학습, 검증 Data의 row index를 array로 반환  \n","for train_index, test_index in kfold.split(X_train):\n","    \n","    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n","    X_train_, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_, y_val = y_train[train_index], y_train[test_index]\n","    \n","    # 학습 및 예측 \n","    svm_clf4.fit(X_train_ , y_train_)    \n","    pred = svm_clf4.predict(X_val)\n","    n_iter += 1\n","    \n","    # 반복 시 마다 정확도 측정 \n","    accuracy = np.round(f1_score(y_val, pred, average='micro'), 4)\n","    train_size = X_train_.shape[0]\n","    test_size = X_val.shape[0]\n","    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n","          .format(n_iter, accuracy, train_size, test_size))\n","    cv_accuracy.append(accuracy)\n","    \n","# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n","print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["데이터 세트 크기: 26049\n","\n","#1 교차 검증 정확도 :0.777, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#2 교차 검증 정확도 :0.7697, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#3 교차 검증 정확도 :0.7864, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#4 교차 검증 정확도 :0.7624, 학습 데이터 크기: 20839, 검증 데이터 크기: 5210\n","\n","#5 교차 검증 정확도 :0.7666, 학습 데이터 크기: 20840, 검증 데이터 크기: 5209\n","\n","## 평균 검증 정확도: 0.77242\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XG14OskJQX-v"},"source":["y_test_predict = svm_clf2.predict(X_test).astype(int)\n","\n","sample_submission['prediction'] = y_test_predict\n","sample_submission.to_csv('submission4.csv', index=False)\n","\n","# Test f1-score: 0.85682"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkXL-9JYQX-v"},"source":[""],"execution_count":null,"outputs":[]}]}